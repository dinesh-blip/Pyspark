#####Problem############
///
Given the problem statement plan a design to approach
Check for memeory total and Vcore total to determine number of concurrent execution that can be forked while launching pyspark shell
Note: Not to use complete capacity until necessary.
determine the data size

///

pyspark --master yarn \
  --conf spark.ui.port=12890 \
  --num-executors 2 \
  --executor-memory 512M \
  --packages com.databricks:spark-avro_2.10:2.0.1

##Orders_data
////
Read order and orders_data
\\\\
filter the data for completed and closed 
orders = sc.textFile("/public/retail_db/orders")
orderItems = sc.textFile("/public/retail_db/order_items")

for i in orders.take(10):print(i)
orders.count()
for i in orderItems.take(10):print(i)
orderItems.count()


////
Filter and map
\\\\
for i in orders.\
map(lambda oi: oi.split(",")[3]).\
distinct(). \
collect():print(i)

ordersFiltered = orders. \
filter(lambda oi: oi.split(",")[3] in ["COMPLETE","CLOSED"])
for i in ordersFiltered.take(10):print(i)
ordersMap = orders.\
map(lambda oi: (int(oi.split(",")[0]),oi.split(",")[])

###########
ordersMap = ordersFiltered. \
map(lambda oi : (int(oi.split(",")[0]), oi.split(",")[1]))

orderItemsMap = orderItems.\
map(lambda ou :(int(ou.split(",")[1]), (int(ou.split(",")[2]), float(ou.split(",")[4]))))

ordersJoin = ordersMap.join(orderItemsMap)
for i in ordersJoin.take(10):print(i)

(4, (u'2013-07-25 00:00:00.0', (897, 49.98)))

ordersJoinMap = ordersJoin.\
map(lambda oa: ((oa[1][0], oa[1][1][0]), oa[1][1][1]))

from operator import add 
dailyRevenuePerroduct = ordersJoinMap.reduceByKey(add)

productsRaw = open("/data/retail_db/products/part-00000").read().splitlines()
products =  sc.parallelize(productsRaw)

#######
'1,2,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy'
#######


productsMap = products.\
map(lambda oe: (int(oe.split(",")[0]), oe.split(",")[2]))

dailyRevenuePerroductMap = dailyRevenuePerroduct.\
map(lambda oa: (oa[0][1],(oa[0][0],oa[1])))

dailyRevenuePerProductJoin = dailyRevenuePerroductMap.join(productsMap)
for i in dailyRevenuePerProductJoin.take(10):print (i)

dailyRevenuePerProduct = dailyRevenuePerProductJoin.\
map(lambda t: ((t[1][0][0], -t[1][0][1]),\
t[1][0][0] + "," + str(t[1][0][1]) + "," + t[1][1])
)

dailyRevenuePerProductSorted = dailyRevenuePerProduct.sortByKey()

dailyRevenuePerProductName = dailyRevenuePerProductSorted.\
map(lambda ra: ra[1])

dailyRevenuePerProductName.saveAsTextFile("/user/itv000439/daily_revenue_txt_python")
dailyRevenuePerProductName.coalesce(2).saveAsTextFile("/user/itv000439/daily_revenue_txt_python")
 

